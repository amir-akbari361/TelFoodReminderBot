import re
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import CallbackQueryHandler
from telegram import InlineKeyboardButton, \
    InlineKeyboardMarkup
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from bs4 import BeautifulSoup
from datetime import datetime, timedelta  # timedelta Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø­Ø°Ù Ú©Ø±Ø¯
from telegram.ext import Application

import os
import time
import signal
import sys
import logging
import asyncio
from telegram.ext import PicklePersistence

import mysql.connector
from mysql.connector import pooling

from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import (
    Application, CommandHandler, MessageHandler,
    ConversationHandler, filters, ContextTypes, CallbackContext
)

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from apscheduler.events import EVENT_JOB_ERROR, EVENT_JOB_EXECUTED

from dotenv import load_dotenv

load_dotenv()

BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

MYSQL_CONFIG = {
    "host": os.getenv("MYSQLHOST"),
    "port": int(os.getenv("MYSQLPORT", "3306")),
    "user": os.getenv("MYSQLUSER"),
    "password": os.getenv("MYSQLPASSWORD"),
    "database": os.getenv("MYSQLDATABASE"),
    "pool_size": 5,
    "pool_name": "mypool",
    "connect_timeout": 30
}

SQLALCHEMY_URL = (
    f"mysql+pymysql://{MYSQL_CONFIG['user']}:{MYSQL_CONFIG['password']}"
    f"@{MYSQL_CONFIG['host']}:{MYSQL_CONFIG['port']}/{MYSQL_CONFIG['database']}"
)

MAX_RETRIES = 3
DB_RECONNECT_INTERVAL = 60  # seconds
# â”€â”€â”€ ÙˆØ¶Ø¹ÛŒØª Ú¯ÙØªÚ¯Ùˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CHOOSING = 0

# â”€â”€â”€ Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MAIN_MARKUP = ReplyKeyboardMarkup([
    ["ØªØºÛŒÛŒØ± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡", "ØºØ°Ø§ÛŒ Ø§Ù…Ø±ÙˆØ²ØŸ"],
    ["ØºØ°Ø§ÛŒ Ø§ÛŒÙ† Ù‡ÙØªÙ‡ØŸ"],
], resize_keyboard=True)

# â”€â”€â”€ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
UNIVERSITY_CONFIG = {
    "Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ": {
        "day_of_week": "wed",  # Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡
        "hour": 12,
        "minute": 0,
        "reminder_message": "â° ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ: Û²Û´ Ø³Ø§Ø¹Øª ØªØ§ Ù¾Ø§ÛŒØ§Ù† Ù…Ù‡Ù„Øª Ø±Ø²Ø±Ùˆ ØºØ°Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡!"
    },
    "ØªÙ‡Ø±Ø§Ù†": {
        "day_of_week": "tue",  # Ø³Ù‡â€ŒØ´Ù†Ø¨Ù‡
        "hour": 12,
        "minute": 0,
        "reminder_message": "â° ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ: Û²Û´ Ø³Ø§Ø¹Øª ØªØ§ Ù¾Ø§ÛŒØ§Ù† Ù…Ù‡Ù„Øª Ø±Ø²Ø±Ùˆ ØºØ°Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ‡Ø±Ø§Ù† Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡!"
    },
}

# â”€â”€â”€ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from zoneinfo import ZoneInfo

    tehran_tz = ZoneInfo("Asia/Tehran")
except ImportError:
    import pytz

    tehran_tz = pytz.timezone("Asia/Tehran")


db_pool = None
bot_app = None
scheduler = AsyncIOScheduler(
    jobstores={
        'default': SQLAlchemyJobStore(url=SQLALCHEMY_URL)
    },
    job_defaults={
        'coalesce': True,
        'misfire_grace_time': 3600
    },
    timezone=tehran_tz
)


# â”€â”€â”€ ØªÙˆØ§Ø¨Ø¹ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ (Ù‡Ù…Ø²Ù…Ø§Ù† Ùˆ ØºÛŒØ±Ù‡Ù…Ø²Ù…Ø§Ù†) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_db_pool():
    global db_pool
    try:
        logging.info("Attempting to initialize database connection pool...")
        db_pool = mysql.connector.pooling.MySQLConnectionPool(**MYSQL_CONFIG)
        conn = db_pool.get_connection()
        if conn.is_connected():
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            cursor.fetchone()
            cursor.close()
            conn.close()
            logging.info("Database connection pool initialized and tested successfully.")
            return True
        else:
            logging.error("Failed to establish a test connection from the pool.")
            return False
    except mysql.connector.Error as err:
        logging.error(f"Error initializing database pool: {err}")
        return False


def get_db_connection():
    global db_pool
    if not db_pool:
        logging.warning("Database pool not initialized. Attempting to initialize.")
        if not init_db_pool():
            logging.error("Failed to re-initialize database pool in get_db_connection.")
            return None
    try:
        conn = db_pool.get_connection()
        if conn.is_connected():
            return conn
        else:  # Ø§ØªØµØ§Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ Ø§Ù…Ø§ Ø¨Ø±Ù‚Ø±Ø§Ø± Ù†ÛŒØ³Øª
            logging.warning("Retrieved a non-connected connection from pool. Re-initializing pool.")
            if init_db_pool():  # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ù…Ø¬Ø¯Ø¯ Ù¾ÙˆÙ„
                return db_pool.get_connection() if db_pool else None
            return None
    except mysql.connector.Error as err:
        logging.error(f"Error getting connection from pool: {err}")
        if err.errno == mysql.connector.errorcode.CR_CONN_HOST_ERROR or \
                err.errno == mysql.connector.errorcode.CR_SERVER_GONE_ERROR:
            logging.info("Attempting to re-initialize DB pool due to connection error.")
            if init_db_pool():
                return db_pool.get_connection() if db_pool else None
        return None


def execute_query(query, params=None, commit=False, fetch=None):
    """Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ Ø¨Ø§ Ø®Ø·Ø§ÛŒØ§Ø¨ÛŒ Ùˆ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ (Ù‡Ù…Ø²Ù…Ø§Ù†)"""
    retries = 0
    while retries < MAX_RETRIES:
        conn = None
        try:
            conn = get_db_connection()
            if not conn:
                logging.error("Database connection error, cannot get connection.")
                time.sleep(retries + 1)  # Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±
                retries += 1
                if retries >= MAX_RETRIES and db_pool:  # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø±ÛŒØ³Øª Ú©Ø±Ø¯Ù† Ù¾ÙˆÙ„ Ù‚Ø¨Ù„ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† ØªÙ„Ø§Ø´
                    logging.warning("Resetting db_pool before last retry")
                    init_db_pool()
                continue

            cursor = conn.cursor()
            cursor.execute(query, params)

            result = None
            if fetch == "one":
                result = cursor.fetchone()
            elif fetch == "all":
                result = cursor.fetchall()

            if commit:
                conn.commit()

            cursor.close()
            return result  # Ù…ÙˆÙÙ‚ÛŒØª Ø¢Ù…ÛŒØ² Ø¨ÙˆØ¯ØŒ Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù† Ùˆ Ø§Ø² Ø­Ù„Ù‚Ù‡ Ø®Ø§Ø±Ø¬ Ø´Ùˆ
        except mysql.connector.Error as err:
            retries += 1
            logging.error(f"Database error (attempt {retries}/{MAX_RETRIES}): {err}")
            if err.errno == mysql.connector.errorcode.ER_LOCK_DEADLOCK or \
                    err.errno == mysql.connector.errorcode.ER_LOCK_WAIT_TIMEOUT:
                time.sleep(retries * 2)  # Ø§Ù†ØªØ¸Ø§Ø± Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ deadlock
            else:
                time.sleep(retries)

            if retries >= MAX_RETRIES:
                logging.error("Maximum database retries reached. Raising exception.")
                raise  # Ù¾Ø³ Ø§Ø² Ø­Ø¯Ø§Ú©Ø«Ø± ØªÙ„Ø§Ø´ØŒ Ø®Ø·Ø§ Ø±Ø§ Ù…Ù†ØªØ´Ø± Ú©Ù†
        finally:
            if conn and conn.is_connected():
                conn.close()
    return None  # Ø§Ú¯Ø± Ø¨Ù‡ Ù‡Ø± Ø¯Ù„ÛŒÙ„ÛŒ (Ù…Ø«Ù„Ø§ Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø§ÙˆÙ„ÛŒÙ‡) Ø¨Ù‡ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø±Ø³Ø¯


# NEW: ØªØ§Ø¨Ø¹ wrapper Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ execute_query Ø¨Ù‡ ØµÙˆØ±Øª ØºÛŒØ±Ù‡Ù…Ø²Ù…Ø§Ù†
async def execute_query_async(query, params=None, commit=False, fetch=None):
    loop = asyncio.get_running_loop()
    try:
        result = await loop.run_in_executor(
            None,  # Uses default ThreadPoolExecutor
            execute_query,
            query,
            params,
            commit,
            fetch
        )
        return result
    except mysql.connector.Error as e:  # Ø§Ú¯Ø± Ø®ÙˆØ¯ execute_query Ø®Ø·Ø§ Ø±Ø§ raise Ú©Ù†Ø¯
        logging.error(f"Async DB call failed after retries: {e}")
        # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ ØªØµÙ…ÛŒÙ… Ø¨Ú¯ÛŒØ±ÛŒØ¯ Ú©Ù‡ Ø®Ø·Ø§ Ø±Ø§ Ù…Ø¬Ø¯Ø¯Ø§ raise Ú©Ù†ÛŒØ¯ ÛŒØ§ None Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯
        # Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ù†ÛŒØ§Ø² Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¯Ø§Ø±Ø¯
        raise


def create_required_tables():
    try:
        # Ø§Ø² Ø¢Ù†Ø¬Ø§ÛŒÛŒ Ú©Ù‡ Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¯Ø± Ø²Ù…Ø§Ù† Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ù‡Ù…Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ
        # Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ù†Ø³Ø®Ù‡ async Ù†ÛŒØ³Øª Ù…Ú¯Ø± Ø§ÛŒÙ†Ú©Ù‡ init_db_pool Ù‡Ù… async Ø´ÙˆØ¯.
        conn = get_db_connection()  # Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø§ÛŒØ¯ Ø¨ØªÙˆØ§Ù†Ø¯ Ù¾ÙˆÙ„ Ø±Ø§ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ù…Ø¬Ø¯Ø¯Ø§ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ú©Ù†Ø¯
        if not conn:
            logging.error("Fatal error: Cannot connect to DB for creating tables.")
            return False

        cursor = conn.cursor()
        users_table = """
        CREATE TABLE IF NOT EXISTS users (
            chat_id BIGINT PRIMARY KEY,
            university VARCHAR(50) NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """
        failed_reminders_table = """
        CREATE TABLE IF NOT EXISTS failed_reminders (
            id INT AUTO_INCREMENT PRIMARY KEY,
            chat_id BIGINT NOT NULL,
            university VARCHAR(50) NOT NULL,
            message TEXT NOT NULL,
            retry_count INT DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            scheduled_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- Ø§ÛŒÙ† ÙÛŒÙ„Ø¯ Ø¯Ø± DDL Ø§ÙˆÙ„ÛŒÙ‡ Ø´Ù…Ø§ Ø¨ÙˆØ¯
            INDEX (chat_id),
            INDEX (retry_count)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """
        cursor.execute(users_table)
        cursor.execute(failed_reminders_table)
        conn.commit()
        cursor.close()
        conn.close()
        logging.info("Required tables checked/created successfully.")
        return True
    except mysql.connector.Error as err:
        logging.error(f"Error creating tables: {err}")
        return False


# ØªÙˆØ§Ø¨Ø¹ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ØºØ°Ø§ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø²ÛŒØ§Ø¯ØŒ Ø¬Ø² ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ execute_query_async)
def clean_food_name(food):
    return re.sub(r"(ØŒ|\(|\[)?\s*(Ø±Ø§ÛŒÚ¯Ø§Ù†|\d{2,3}(,\d{3})?)\s*(ØªÙˆÙ…Ø§Ù†|Ø±ÛŒØ§Ù„)?\)?$", "", food).strip()


def get_today_name():
    """Ø¯Ø±ÛŒØ§ÙØª Ù†Ø§Ù… Ø±ÙˆØ² Ù‡ÙØªÙ‡ Ø§Ù…Ø±ÙˆØ² Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ"""
    today = datetime.now()
    weekday = today.weekday()

    days_mapping = {
        0: "Ø¯ÙˆØ´Ù†Ø¨Ù‡",
        1: "Ø³Ù‡ Ø´Ù†Ø¨Ù‡",
        2: "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡",
        3: "Ù¾Ù†Ø¬ Ø´Ù†Ø¨Ù‡",
        4: "Ø¬Ù…Ø¹Ù‡",
        5: "Ø´Ù†Ø¨Ù‡",
        6: "ÛŒÚ©Ø´Ù†Ø¨Ù‡"
    }

    return days_mapping[weekday]


def parse_food_schedule(html, university=None):
    try:
        soup = BeautifulSoup(html, "html.parser")
        schedule = {}

        day_containers = soup.find_all("div", class_="dayContainer")

        for day_container in day_containers:
            day_span = day_container.find(class_="day")
            date_span = day_container.find(class_="date")

            if day_span:
                day_name = day_span.get_text(strip=True)
                date = date_span.get_text(strip=True) if date_span else ""

                schedule[day_name] = {
                    "ØªØ§Ø±ÛŒØ®": date,
                    "ØµØ¨Ø­Ø§Ù†Ù‡": [],
                    "Ù†Ø§Ù‡Ø§Ø±": [],
                    "Ø´Ø§Ù…": []
                }

                current_element = day_container

                while True:
                    current_element = current_element.find_next_sibling()
                    if not current_element or (
                            current_element.get('class') and 'dayContainer' in current_element.get('class')):
                        break

                    time_meal = current_element.find("span", class_="TimeMeal")
                    current_meal_type = None

                    if time_meal:
                        meal_text = time_meal.get_text(strip=True).lower()
                        if "ØµØ¨Ø­Ø§Ù†Ù‡" in meal_text:
                            current_meal_type = "ØµØ¨Ø­Ø§Ù†Ù‡"
                        elif "Ù†Ø§Ù‡Ø§Ø±" in meal_text or "Ù†Ù‡Ø§Ø±" in meal_text:
                            current_meal_type = "Ù†Ø§Ù‡Ø§Ø±"
                        elif "Ø´Ø§Ù…" in meal_text:
                            current_meal_type = "Ø´Ø§Ù…"

                    if current_meal_type:
                        meal_divs = current_element.find_all("div", id="MealDiv")
                        for meal_div in meal_divs:
                            food_labels = meal_div.find_all("label", class_="reserveFoodCheckBox")
                            for label in food_labels:
                                if label.get('for') and label.get_text(strip=True):
                                    food_text = clean_food_name(label.get_text(strip=True))
                                    if food_text and food_text not in schedule[day_name][current_meal_type]:
                                        schedule[day_name][current_meal_type].append(food_text)

        return schedule

    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡ ØºØ°Ø§ÛŒÛŒ: {e}")
        return {
            day: {"ØªØ§Ø±ÛŒØ®": "", "ØµØ¨Ø­Ø§Ù†Ù‡": [], "Ù†Ø§Ù‡Ø§Ø±": [], "Ø´Ø§Ù…": []}
            for day in ["Ø´Ù†Ø¨Ù‡", "ÛŒÚ©Ø´Ù†Ø¨Ù‡", "Ø¯ÙˆØ´Ù†Ø¨Ù‡", "Ø³Ù‡ Ø´Ù†Ø¨Ù‡", "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡", "Ù¾Ù†Ø¬ Ø´Ù†Ø¨Ù‡"]
        }


def merge_weekly_menus(menu1, menu2):
    merged_menu = {}

    # ØªØ±ØªÛŒØ¨ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
    days_order = ["Ø´Ù†Ø¨Ù‡", "ÛŒÚ©Ø´Ù†Ø¨Ù‡", "Ø¯ÙˆØ´Ù†Ø¨Ù‡", "Ø³Ù‡ Ø´Ù†Ø¨Ù‡", "Ú†Ù‡Ø§Ø±Ø´Ù†Ø¨Ù‡", "Ù¾Ù†Ø¬ Ø´Ù†Ø¨Ù‡", "Ø¬Ù…Ø¹Ù‡"]

    # ØªØ±Ú©ÛŒØ¨ Ù‡Ù…Ù‡ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù‡Ø± Ø¯Ùˆ Ù…Ù†Ùˆ
    all_days = set(menu1.keys()) | set(menu2.keys())

    # Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù…Ø±ØªØ¨ Ø´Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ±ØªÛŒØ¨ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù‡ÙØªÙ‡
    for day in days_order:
        if day in all_days:
            merged_menu[day] = {
                'ØªØ§Ø±ÛŒØ®': menu1.get(day, {}).get('ØªØ§Ø±ÛŒØ®', '') or menu2.get(day, {}).get('ØªØ§Ø±ÛŒØ®', ''),
                'ØµØ¨Ø­Ø§Ù†Ù‡': menu1.get(day, {}).get('ØµØ¨Ø­Ø§Ù†Ù‡', []),
                'Ù†Ø§Ù‡Ø§Ø±': menu1.get(day, {}).get('Ù†Ø§Ù‡Ø§Ø±', []),
                'Ø´Ø§Ù…': menu2.get(day, {}).get('Ø´Ø§Ù…', [])
            }
    return merged_menu


def format_meals(meals):
    """Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ ÙˆØ¹Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØºØ°Ø§ÛŒÛŒ"""
    if not meals:
        return "âš ï¸ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù†Ùˆ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª"

    message = ""
    message += "ğŸ³ ØµØ¨Ø­Ø§Ù†Ù‡:\n"
    message += "".join(f"    â€¢ {f}\n" for f in meals['ØµØ¨Ø­Ø§Ù†Ù‡']) or "    â€¢ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª\n"
    message += "ğŸ› Ù†Ø§Ù‡Ø§Ø±:\n"
    message += "".join(f"    â€¢ {f}\n" for f in meals['Ù†Ø§Ù‡Ø§Ø±']) or "    â€¢ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª\n"
    message += "ğŸ² Ø´Ø§Ù…:\n"
    message += "".join(f"    â€¢ {f}\n" for f in meals['Ø´Ø§Ù…']) or "    â€¢ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª\n"
    return message


async def handle_food_query(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù…Ù†ÙˆÛŒ ØºØ°Ø§"""
    try:
        chat_id = update.effective_chat.id
        message_text = update.message.text.lower()
        is_today = "Ø§Ù…Ø±ÙˆØ²" in message_text or "today" in message_text

        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ú©Ø§Ø±Ø¨Ø±
        university_result = execute_query(
            "SELECT university FROM users WHERE chat_id = %s",
            (chat_id,),
            fetch="one"
        )

        if not university_result:
            await update.message.reply_text(
                "Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ÛŒØ¯ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯. Ø§Ø² Ø¯Ø³ØªÙˆØ± /start Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.",
                reply_markup=MAIN_MARKUP
            )
            return

        university = university_result[0]

        # Ø¯Ø±ÛŒØ§ÙØª Ù…Ù†ÙˆÛŒ ØºØ°Ø§
        try:
            if university == "Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ":
                with open("kharazmi_menu.html", "r", encoding="utf-8") as f:
                    html = f.read()
            else:
                with open("tehran_menu_lunch.html", "r", encoding="utf-8") as f:
                    html_lunch = f.read()
                with open("tehran_menu_dinner.html", "r", encoding="utf-8") as f:
                    html_dinner = f.read()
        except FileNotFoundError:
            logging.error(f"ÙØ§ÛŒÙ„ Ù…Ù†ÙˆÛŒ {university} ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            await update.message.reply_text(
                f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù†ÙˆÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ {university} Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø¹Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.",
                reply_markup=MAIN_MARKUP
            )
            return

        # Ù¾Ø±Ø¯Ø§Ø²Ø´ HTML Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø±Ù†Ø§Ù…Ù‡ ØºØ°Ø§ÛŒÛŒ
        if (university == "Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ"):
            schedule = parse_food_schedule(html, university)
        else:
            temp1 = parse_food_schedule(html_lunch, university)
            temp2 = parse_food_schedule(html_dinner, university)
            schedule = merge_weekly_menus(temp1, temp2)

        if is_today:
            today_name = get_today_name()
            if today_name == "Ø¬Ù…Ø¹Ù‡":
                await update.message.reply_text("ğŸ“µ Ø§Ù…Ø±ÙˆØ² (Ø¬Ù…Ø¹Ù‡) ØºØ°Ø§ Ø³Ø±Ùˆ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.", reply_markup=MAIN_MARKUP)
                return

            # Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ‡Ø±Ø§Ù†
            if university == "ØªÙ‡Ø±Ø§Ù†" and today_name not in schedule:
                await update.message.reply_text(f"ğŸ“µ Ø§Ù…Ø±ÙˆØ² ({today_name}) Ø¯Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ‡Ø±Ø§Ù† ØºØ°Ø§ Ø³Ø±Ùˆ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.",
                                                reply_markup=MAIN_MARKUP)
                return

            meals = schedule.get(today_name, {})
            response = f"ğŸ½ Ù…Ù†ÙˆÛŒ Ø§Ù…Ø±ÙˆØ² ({today_name}) Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ {university}:\n\n"
            response += format_meals(meals)
        else:

            response = f"ğŸ—“ Ù…Ù†ÙˆÛŒ Ù‡ÙØªÙ‡ Ø¬Ø§Ø±ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ {university}:\n\n"
            for day, meals in schedule.items():
                response += f"ğŸ“… {day}:\n{format_meals(meals)}\n\n"

        await update.message.reply_text(response, reply_markup=MAIN_MARKUP)

    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„ ØºØ°Ø§: {e}")
        await update.message.reply_text(
            "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØºØ°Ø§ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.",
            reply_markup=MAIN_MARKUP
        )


async def today_food(update: Update, context: ContextTypes.DEFAULT_TYPE):
    update.message.text = "ØºØ°Ø§ÛŒ Ø§Ù…Ø±ÙˆØ²"  # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ handle_food_query
    await handle_food_query(update, context)


async def week_food(update: Update, context: ContextTypes.DEFAULT_TYPE):
    update.message.text = "ØºØ°Ø§ÛŒ Ø§ÛŒÙ† Ù‡ÙØªÙ‡"  # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ handle_food_query
    await handle_food_query(update, context)


def setup_food_handlers(application):
    """Ø«Ø¨Øª ØªÙ…Ø§Ù… Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ ØºØ°Ø§"""
    application.add_handler(CommandHandler("today", today_food))
    application.add_handler(CommandHandler("week", week_food))
    application.add_handler(MessageHandler(filters.Regex(r'^(ØºØ°Ø§ÛŒ Ø§Ù…Ø±ÙˆØ²|Ù…Ù†ÙˆÛŒ Ø§Ù…Ø±ÙˆØ²)$'), today_food))
    application.add_handler(MessageHandler(filters.Regex(r'^(ØºØ°Ø§ÛŒ Ù‡ÙØªÙ‡|Ù…Ù†ÙˆÛŒ Ù‡ÙØªÙ‡)$'), week_food))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_food_query))


# â”€â”€â”€ ØªÙˆØ§Ø¨Ø¹ Ù„Ø§Ú¯ÛŒÙ†Ú¯ Ùˆ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ (ØªØºÛŒÛŒØ±Ø§Øª Ø¹Ù…Ø¯Ù‡) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def setup_logging():
    logging.basicConfig(
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        level=logging.INFO,
        handlers=[logging.StreamHandler(sys.stdout)]  # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù„Ø§Ú¯ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„
    )
    logging.getLogger('apscheduler').setLevel(logging.WARNING)
    logging.getLogger('mysql.connector').setLevel(logging.WARNING)  # Ú©Ø§Ù‡Ø´ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ mysql


async def job_listener(event):
    if event.exception:
        logging.error(f"Job ID {event.job_id} failed: {event.exception}")
    else:
        logging.info(f"Job ID {event.job_id} executed successfully.")


# NEW: Helper function to get user chat_ids for a university asynchronously
async def get_user_chat_ids_for_university_async(university_name: str) -> list[int]:
    query = "SELECT chat_id FROM users WHERE university = %s"
    params = (university_name,)
    try:
        result = await execute_query_async(query, params, fetch="all")
        return [row[0] for row in result] if result else []
    except Exception as e:  # Ø§Ú¯Ø± execute_query_async Ø®Ø·Ø§ Ø±Ø§ raise Ú©Ù†Ø¯
        logging.error(f"Failed to get users for {university_name}: {e}")
        return []


# NEW: Helper function to save a failed reminder asynchronously
async def save_failed_reminder_async(chat_id: int, university: str, message: str):
    query = "INSERT INTO failed_reminders (chat_id, university, message) VALUES (%s, %s, %s)"
    params = (chat_id, university, message)
    try:
        await execute_query_async(query, params, commit=True)
        logging.info(f"Saved failed reminder for chat_id {chat_id} ({university}) to DB.")
    except Exception as e:  # Ø§Ú¯Ø± execute_query_async Ø®Ø·Ø§ Ø±Ø§ raise Ú©Ù†Ø¯
        logging.error(f"Error saving failed reminder for chat_id {chat_id} to DB: {e}")


async def send_reminders_to_university_users(university_name: str):  # <<-- Ù¾Ø§Ø±Ø§Ù…ØªØ± context Ø­Ø°Ù Ø´Ø¯
    global bot_app  # Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ØªØºÛŒØ± Ú¯Ù„ÙˆØ¨Ø§Ù„
    if not bot_app or not bot_app.bot:
        logging.error(f"bot_app not properly initialized. Cannot send reminders for {university_name}.")
        return

    bot = bot_app.bot
    # logging.info(f"Job started: Sending reminders for university: {university_name} using bot: {await bot.get_my_name()}") # get_my_name async Ø§Ø³Øª
    logging.info(f"Job started: Sending reminders for university: {university_name}")

    config = UNIVERSITY_CONFIG.get(university_name)
    if not config:
        logging.error(f"University config not found for {university_name}. Aborting job.")
        return

    message_text = config['reminder_message']
    user_chat_ids = await get_user_chat_ids_for_university_async(university_name)

    if not user_chat_ids:
        logging.info(f"No users found for university: {university_name}. Job finished.")
        return

    logging.info(f"Found {len(user_chat_ids)} users for {university_name}. Starting to send messages.")
    successful_sends = 0
    failed_sends = 0

    for chat_id in user_chat_ids:
        try:
            await bot.send_message(chat_id=chat_id, text=message_text)
            successful_sends += 1
            logging.debug(f"Reminder sent to {chat_id} for {university_name}")
            await asyncio.sleep(0.1)
        except Exception as e:
            failed_sends += 1
            logging.error(f"Failed to send reminder to {chat_id} ({university_name}): {e}")
            await save_failed_reminder_async(chat_id, university_name, message_text)

    logging.info(
        f"Job finished for {university_name}. Successful sends: {successful_sends}, Failed attempts: {failed_sends}")


def schedule_university_wide_reminders(university_name: str,
                                       application: Application):  # application Ø¨Ø±Ø§ÛŒ Ù„Ø§Ú¯ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ù…ÙÛŒØ¯ Ø§Ø³Øª
    config = UNIVERSITY_CONFIG.get(university_name)
    if not config:
        logging.error(f"Cannot schedule reminders: Config not found for {university_name}")
        return

    job_id = f"university_reminder_{university_name}"

    scheduler.add_job(
        send_reminders_to_university_users,
        'cron',
        day_of_week=config['day_of_week'],
        hour=config['hour'],
        minute=config['minute'],
        id=job_id,
        kwargs={'university_name': university_name},
        replace_existing=True,
        misfire_grace_time=300
    )
    logging.info(
        f"Scheduled/Updated university-wide reminder: {job_id} for {university_name} at {config['day_of_week']} {config['hour']}:{config['minute']}")


async def retry_failed_reminders():
    global bot_app  # Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ØªØºÛŒØ± Ú¯Ù„ÙˆØ¨Ø§Ù„
    if not bot_app or not bot_app.bot:
        logging.error("bot_app not properly initialized. Cannot retry failed reminders.")
        return

    bot = bot_app.bot
    logging.info("Starting retry_failed_reminders job.")
    try:
        failed_reminders = await execute_query_async(
            "SELECT id, chat_id, university, message, retry_count FROM failed_reminders WHERE retry_count < %s",
            (MAX_RETRIES,),
            fetch="all"
        )
        if not failed_reminders:
            logging.info("No failed reminders to retry.")
            return

        logging.info(f"Retrying {len(failed_reminders)} failed reminders.")
        retried_successfully = 0
        still_failed = 0

        for reminder_data in failed_reminders:
            reminder_id, chat_id, university, message, retry_count = reminder_data
            try:
                await bot.send_message(chat_id=chat_id, text=message)
                logging.info(f"Successfully retried reminder_id {reminder_id} for user {chat_id}")
                await execute_query_async(
                    "DELETE FROM failed_reminders WHERE id = %s", (reminder_id,), commit=True
                )
                retried_successfully += 1
            except Exception as e:
                still_failed += 1
                logging.warning(f"Failed again to retry reminder_id {reminder_id} for user {chat_id}: {e}")
                new_retry_count = retry_count + 1
                await execute_query_async(
                    "UPDATE failed_reminders SET retry_count = %s WHERE id = %s",
                    (new_retry_count, reminder_id), commit=True
                )
                if new_retry_count >= MAX_RETRIES:
                    logging.error(f"Max retries reached for reminder_id {reminder_id} (user {chat_id}). Giving up.")
            await asyncio.sleep(0.2)  # Ú©Ù…ÛŒ ØªØ§Ø®ÛŒØ± Ø¨ÛŒÙ† ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø¯Ø¯
        logging.info(
            f"Finished retry_failed_reminders job. Retried successfully: {retried_successfully}, Still failed/marked for no more retries: {still_failed}")

    except mysql.connector.Error as db_err:
        logging.error(f"Database error in retry_failed_reminders: {db_err}")
    except Exception as e:
        logging.error(f"Unexpected error in retry_failed_reminders: {e}", exc_info=True)


async def on_startup(application: Application):

    if not scheduler.running: # ÙÙ‚Ø· Ø§Ú¯Ø± scheduler Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ù†ÛŒØ³ØªØŒ Ø¢Ù† Ø±Ø§ start Ú©Ù†
        try:
            scheduler.start()
            logging.info("APScheduler started successfully.")
        except Exception as e:
            logging.critical(f"Failed to start APScheduler: {e}", exc_info=True)
            return
    if not scheduler._listeners:  # ÛŒÚ© Ø±Ø§Ù‡ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ listener Ù‡Ø§ Ù‚Ø¨Ù„Ø§ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
        scheduler.add_listener(job_listener, EVENT_JOB_ERROR | EVENT_JOB_EXECUTED)
        logging.info("APScheduler event listener added.")

    # Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡
    for uni_name in UNIVERSITY_CONFIG.keys():
        schedule_university_wide_reminders(uni_name, application)

    # ÛŒÚ© Ø¬Ø§Ø¨ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ØŒ Ù…Ø«Ù„Ø§ Ù‡Ø± ÛŒÚ© Ø³Ø§Ø¹Øª ÛŒØ§ Ú©Ù…ØªØ±
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ job_id ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨Ø§Ø´Ø¯ ÛŒØ§ replace_existing=True Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯
    retry_job_id = "retry_failed_reminders_job"
    # ÙÙ‚Ø· Ø§Ú¯Ø± Ø¬Ø§Ø¨ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†. replace_existing=True Ù‡Ù… Ù‡Ù…ÛŒÙ† Ú©Ø§Ø± Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    scheduler.add_job(
        retry_failed_reminders,
        'interval',
        minutes=30,
        id=retry_job_id,
        replace_existing=True
    )
    logging.info(f"Scheduled job for retrying failed reminders: {retry_job_id}")

    # Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù…ÙˆØ§Ø±Ø¯ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¯Ø± Ø²Ù…Ø§Ù† Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ
    # Ø§ÛŒÙ† Ø¯ÛŒÚ¯Ø± Ù„Ø§Ø²Ù… Ù†ÛŒØ³Øª Ø§Ú¯Ø± Ø¬Ø§Ø¨ Ø¨Ø§Ù„Ø§ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ú©Ø§Ø± Ú©Ù†Ø¯ Ùˆ Ø¯Ø± Ø§ÙˆÙ„ÛŒÙ† Ø§Ø¬Ø±Ø§ Ù…ÙˆØ§Ø±Ø¯ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†Ø¯
    # await retry_failed_reminders(application)

    jobs = scheduler.get_jobs()
    logging.info(f"Total jobs in scheduler after startup: {len(jobs)}")
    for job in jobs:
        logging.info(f"  Job ID: {job.id}, Next run: {job.next_run_time}, Trigger: {str(job.trigger)}")


async def shutdown_operations(application: Application):  # application Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù† Ù¾Ø§Ø³ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    logging.info("Bot is shutting down...")
    if scheduler and scheduler.running:
        scheduler.shutdown()
        logging.info("APScheduler shut down.")

    logging.info("Shutdown complete.")


# â”€â”€â”€ Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    logging.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø³ØªÙˆØ± start Ø§Ø² {update.effective_chat.id}")
    try:
        await update.message.reply_text(
            "ğŸ‘‹ Ø³Ù„Ø§Ù…! Ù„Ø·ÙØ§Ù‹ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
            reply_markup=ReplyKeyboardMarkup(
                [["Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ", "ØªÙ‡Ø±Ø§Ù†"]],
                one_time_keyboard=True,
                resize_keyboard=True
            )
        )
        return CHOOSING
    except Exception as e:
        logging.error(f"error on start: {e}")
        raise


async def choose_university(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    uni = update.message.text
    chat_id = update.effective_chat.id

    if uni not in UNIVERSITY_CONFIG:
        await update.message.reply_text("Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³ØªØŒ Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:")
        return CHOOSING

    try:
        # MODIFIED: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² execute_query_async
        await execute_query_async(
            "INSERT INTO users (chat_id, university) VALUES (%s, %s) ON DUPLICATE KEY UPDATE university = %s",
            (chat_id, uni, uni),
            commit=True
        )
        logging.info(f"User {chat_id} selected/updated university to {uni}")



        await update.message.reply_text(
            f"Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ {uni} Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯. Ù…Ù† Ø¨Ù‡ Ø´Ù…Ø§ ÛŒØ§Ø¯Ø¢ÙˆØ±ÛŒ Ø±Ø²Ø±Ùˆ ØºØ°Ø§ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø±Ø§ Ø¯Ø± Ø²Ù…Ø§Ù† Ù…Ù†Ø§Ø³Ø¨ Ø§Ø±Ø³Ø§Ù„ Ø®ÙˆØ§Ù‡Ù… Ú©Ø±Ø¯.",
            reply_markup=MAIN_MARKUP
        )
        return ConversationHandler.END
    except mysql.connector.Error as db_err:
        logging.error(f"DB error choosing university for {chat_id}: {db_err}")
        await update.message.reply_text("Ù…Ø´Ú©Ù„ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ù…Ø§. Ù„Ø·ÙØ§ Ø¨Ø¹Ø¯Ø§ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")
        return CHOOSING  # ÛŒØ§ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ø­Ø§Ù„Øª Ø§ÙˆÙ„ÛŒÙ‡
    except Exception as e:
        logging.error(f"Error in choose_university for {chat_id}: {e}", exc_info=True)
        await update.message.reply_text("Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯. Ù„Ø·ÙØ§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")
        return CHOOSING


async def cancel_conversation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Ù¾Ø§ÛŒØ§Ù† Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ú¯ÙØªÚ¯Ùˆ."""
    await update.message.reply_text("Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.", reply_markup=MAIN_MARKUP)
    return ConversationHandler.END


# â”€â”€â”€ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    setup_logging()

    if not BOT_TOKEN:
        logging.critical("BOT_TOKEN not found in environment variables. Exiting.")
        sys.exit(1)

    if not init_db_pool():
        logging.critical("Failed to initialize database pool on startup. Exiting.")
        sys.exit(1)

    if not create_required_tables():
        logging.critical("Failed to create required database tables. Exiting.")
        sys.exit(1)

    persistence = PicklePersistence(filepath="conversation_states")

    application = (
        Application.builder()
        .token(BOT_TOKEN)
        .persistence(persistence)
        .post_init(on_startup)
        .post_shutdown(shutdown_operations)
        .build()
    )

    bot_app = application

    conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler("start", start),
            MessageHandler(filters.Regex(r'^(ØªØºÛŒÛŒØ± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡|Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡)$'), start)
        ],
        states={
            CHOOSING: [MessageHandler(filters.Regex(r'^(Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ|ØªÙ‡Ø±Ø§Ù†)$'), choose_university)],
        },
        fallbacks=[CommandHandler("cancel", cancel_conversation)],
        name="university_choice_conversation",
        persistent=True
    )
    application.add_handler(conv_handler)

    application.add_handler(MessageHandler(filters.Regex(".*ØºØ°Ø§ÛŒ Ø§Ù…Ø±ÙˆØ².*"), handle_food_query))
    application.add_handler(MessageHandler(filters.Regex(".*ØºØ°Ø§ÛŒ Ø§ÛŒÙ† Ù‡ÙØªÙ‡.*"), handle_food_query))

    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_food_query))



    logging.info("Bot is starting polling...")
    try:
        application.run_polling(allowed_updates=Update.ALL_TYPES)
    except Exception as e:
        logging.critical(f"Bot failed to run: {e}", exc_info=True)
        sys.exit(1)
